# 3data/data_analysis.py ê¸°ë°˜ ì½”ë“œ
# Streamlit Cloudì—ì„œ Gemini API Key, MCP URL í™˜ê²½ë³€ìˆ˜ ì„¤ì • í•„ìš”
# Streamlit ì•±ìœ¼ë¡œ FastMCP Tool Calling í†µí•©
# ë¹„ë™ê¸° ë°©ì‹ìœ¼ë¡œ(ì„œë²„ì—ì„œ ë°ì´í„° ë°›ì•„ì˜¤ëŠ” ë™ì•ˆ UI ë©ˆì¶”ì§€ ì•Šê³  ê³„ì† ëŒì•„ê°€ë„ë¡) Gemini APIì™€ MCP Tool í˜¸ì¶œ ì—°ë™



# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
import streamlit as st
import time
from fastmcp import Client
import json
import asyncio
from typing import List, Dict, Any
from google import genai



# --- í™˜ê²½ë³€ìˆ˜ ì„¤ì • ---
MCP_SERVER_URL = st.secrets.mcp_server_url  
api_key = st.secrets.gemini_api_key



# --- FastMCP ì„œë²„, Gemini ì„¤ì • ---
mcp_client = Client(
    MCP_SERVER_URL
)

gemini_client = genai.Client(api_key=api_key)



# --- FastMCP Tool í˜¸ì¶œ í•¨ìˆ˜ ---
async def async_tool_call(client: Client, tool_name: str, tool_args: Dict[str, Any]) -> Any:
    """FastMCP í´ë¼ì´ì–¸íŠ¸ë¥¼ ì „ë‹¬ë°›ì•„ íŠ¹ì • íˆ´ì„ í˜¸ì¶œí•©ë‹ˆë‹¤."""
    result = await client.call_tool(tool_name, tool_args)
    return result.data



# --- ëŒ€í™” ê¸°ë¡ ê´€ë¦¬ ë¡œì§ ---

# ëŒ€í™” ê¸°ë¡ì„ ì €ì¥í•  ê³µê°„ ë§Œë“¤ê¸° (session_state ì‚¬ìš©)
if "chat_sessions" not in st.session_state:
    # {ì„¸ì…˜ID: {"title": "ì œëª©", "messages": [...]}}
    st.session_state.chat_sessions = {}
    
if "current_session_id" not in st.session_state:
    st.session_state.current_session_id = None
    
def new_chat_session():
    """ìƒˆë¡œìš´ ì±„íŒ… ì„¸ì…˜ì„ ìƒì„±í•˜ê³  í™œì„±í™”í•©ë‹ˆë‹¤."""
    # ê³ ìœ í•œ ì„¸ì…˜ ID ìƒì„±
    new_id = f"chat_{int(time.time() * 1000)}" 
    st.session_state.chat_sessions[new_id] = {
        "title": "ìƒˆ ëŒ€í™”", 
        "messages": []
    }
    st.session_state.current_session_id = new_id

# ì•± ì‹œì‘ ì‹œ ë˜ëŠ” ì„¸ì…˜ì´ ì—†ì„ ê²½ìš° ìƒˆ ì„¸ì…˜ ìƒì„±
if st.session_state.current_session_id is None or st.session_state.current_session_id not in st.session_state.chat_sessions:
    new_chat_session()
    
# í˜„ì¬ í™œì„± ì„¸ì…˜ì˜ ë©”ì‹œì§€ ëª©ë¡ì„ ì§§ê²Œ ì°¸ì¡°
current_session = st.session_state.chat_sessions[st.session_state.current_session_id]
current_messages = current_session["messages"]



# --- ì‚¬ì´ë“œë°” ---

# ì‚¬ì´ë“œë°” - ì„¸ì…˜ ê´€ë¦¬
st.sidebar.title("ğŸ’¬ ëŒ€í™” ê¸°ë¡")
if st.sidebar.button("â• ìƒˆ ëŒ€í™” ì‹œì‘"):
    new_chat_session()
    st.rerun()

st.sidebar.caption("âš ï¸ ì´ ê¸°ë¡ì€ ë¸Œë¼ìš°ì €ë¥¼ ë‹«ìœ¼ë©´ ì‚¬ë¼ì§‘ë‹ˆë‹¤.")

# ëŒ€í™” ëª©ë¡ í‘œì‹œ ë° ì„ íƒ
for session_id, session_data in st.session_state.chat_sessions.items():
    if st.sidebar.button(
        session_data["title"], 
        key=session_id,
        use_container_width=True,
        # í˜„ì¬ ì„¸ì…˜ ê°•ì¡° í‘œì‹œ (ì„ íƒ ì‚¬í•­)
        # help="í´ë¦­í•˜ì—¬ ëŒ€í™”ë¡œ ì´ë™" 
    ):
        st.session_state.current_session_id = session_id
        st.rerun()



# --- ë¹„ë™ê¸° ì±—ë´‡ ì‘ë‹µ ìƒì„± í•¨ìˆ˜ ---

async def generate_chat_response_async(messages: List[Dict[str, str]], system_prompt: str):
    """
    ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Gemini APIì™€ FastMCP Tool Callingì„ í†µí•©í•˜ì—¬ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    full_history = []
    for m in messages:
        role = "model" if m["role"] == "assistant" else m["role"]
        full_history.append(genai.types.Content(role=role, parts=[genai.types.Part.from_text(text=m["content"])]))

    async with mcp_client:
        response = await gemini_client.aio.models.generate_content(
            model="gemini-2.5-pro",
            contents=full_history,
            config=genai.types.GenerateContentConfig(
                system_instruction=system_prompt,
                temperature=0,
                tools=[mcp_client.session]  # MCP ì„¸ì…˜ì„ Tool ì •ì˜ë¡œ ì „ë‹¬
            )
        )

        # Tool í˜¸ì¶œ ë£¨í”„
        while getattr(response, "function_calls", None): 
            tool_results = []
            full_history.append(response.candidates[0].content) 
            
            for call in response.function_calls: 
                tool_name = call.name 
                tool_args = dict(call.args) 
                
                try: 
                    tool_output = await async_tool_call(mcp_client, tool_name, tool_args) 
                    if not isinstance(tool_output, (str, bytes)): 
                        tool_output = json.dumps(tool_output, ensure_ascii=False, indent=2) 
                except Exception as e: tool_output = f"Tool ì‹¤í–‰ ì˜¤ë¥˜ ({tool_name}): {e}" 

                tool_results.append(
                    genai.types.Part.from_function_response(
                        name=tool_name,
                        response=tool_output
                    )
                )

            # Tool ê²°ê³¼ë¥¼ Geminiì— ì¬ì „ë‹¬
            full_history.append(genai.types.Content(role="tool", parts=tool_results))
            response = await gemini_client.aio.models.generate_content(
                model="gemini-2.5-pro",
                contents=full_history,
                config=genai.types.GenerateContentConfig(
                    system_instruction=system_prompt,
                    temperature=0,
                    tools=[mcp_client.session]
                )
            )

    return response.text


# --- Streamlitìš© ë™ê¸° ë˜í¼ í•¨ìˆ˜ ---
def run_async(coro):
    """Streamlit ë‚´ì—ì„œ asyncio.run() ì¶©ëŒ ì—†ì´ ì‹¤í–‰"""
    try:
        loop = asyncio.get_running_loop()
    except RuntimeError:
        loop = None

    if loop and loop.is_running():
        return asyncio.ensure_future(coro)
    else:
        return asyncio.run(coro)


def generate_chat_response(messages: List[Dict[str, str]], system_prompt: str):
    return run_async(generate_chat_response_async(messages, system_prompt))



# --- ë©”ì¸ ì±—ë´‡ ì¸í„°í˜ì´ìŠ¤ ---

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ìœ íŠœë¸Œ ë°ì´í„° ë¶„ì„ ì±—ë´‡", page_icon="ğŸ“Š")

# ì œëª© í‘œì‹œ
st.title("ğŸ“Š ìœ íŠœë¸Œ ë°ì´í„° ë¶„ì„ ì±—ë´‡")
st.write(f"**{current_session['title']}**")

# ì´ì „ ëŒ€í™” ë‚´ìš© í™”ë©´ì— í‘œì‹œí•˜ê¸°
for message in current_messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜
system_prompt = """
ë‹¹ì‹ ì€ ìœ íŠœë¸Œ ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¹ì‹ ì˜ ì—­í• ì€ YouTube ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

ë°ì´í„°ëŠ” ë‹¤ìŒ 4ê°€ì§€ ì¶œì²˜ ì¤‘ í•˜ë‚˜ ë˜ëŠ” ì—¬ëŸ¬ ê°œê°€ í¬í•¨ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
1. get_youtube_transcript â†’ ì˜ìƒ ìë§‰ ì „ì²´ í…ìŠ¤íŠ¸
2. search_youtube_videos â†’ ê²€ìƒ‰ëœ ì˜ìƒ ë¦¬ìŠ¤íŠ¸ (ì œëª©, ì¡°íšŒìˆ˜, ì±„ë„ëª…, ì¢‹ì•„ìš” ìˆ˜ ë“±)
3. get_channel_info â†’ ì±„ë„ ê¸°ë³¸ ì •ë³´ ë° ìµœê·¼ ì˜ìƒ
4. get_youtube_comments â†’ ëŒ“ê¸€ ë‚´ìš©, ì¢‹ì•„ìš” ìˆ˜, ì‘ì„±ì ë“±

---

### ë¶„ì„ ë‹¨ê³„
1. ë°ì´í„° íŒŒì•…: ì–´ë–¤ MCP Toolì˜ ê²°ê³¼ì¸ì§€ ì‹ë³„í•˜ê³ , í•„ìš”ì‹œ ì—¬ëŸ¬ ë„êµ¬ì˜ ë°ì´í„°ë¥¼ ê²°í•©í•´ ë¬¸ë§¥ì ìœ¼ë¡œ ì´í•´í•©ë‹ˆë‹¤.
2. ìš”ì•½ / ê°œìš” ìƒì„±: ìë§‰ì€ í•µì‹¬ ì£¼ì œë¥¼, ì˜ìƒ ë¦¬ìŠ¤íŠ¸ëŠ” íŠ¹ì§•ì„, ëŒ“ê¸€ì€ ê°ì„±/í‚¤ì›Œë“œë¥¼ ìš”ì•½í•©ë‹ˆë‹¤.
3. ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ: ì˜ìƒì˜ í•µì‹¬ ë©”ì‹œì§€, íƒ€ê²Ÿ ì‹œì²­ì, ì±„ë„ì˜ ì„±ì¥ ë°©í–¥ ë“±ì„ ë¶„ì„í•©ë‹ˆë‹¤.
4. ìµœì¢… ì¶œë ¥ í˜•íƒœ: ë¶„ì„ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì²´ì ì¸ ìœ íŠœë¸Œ ë°ì´í„° ë¶„ì„ ë³´ê³ ì„œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.

---

### ì£¼ì˜ì‚¬í•­
- ë°ì´í„°ê°€ ì¼ë¶€ ëˆ„ë½ë˜ì—ˆì„ ê²½ìš°, ê°€ëŠ¥í•œ ì •ë³´ë§Œ í™œìš©í•˜ê³  ë°ì´í„° ë¶€ì¡±ì´ë¼ê³  ëª…ì‹œí•©ë‹ˆë‹¤.
- ëŒ“ê¸€ ë¶„ì„ ì‹œ ìš•ì„¤, ì¸ì‹ ê³µê²© ë“±ì€ ì œì™¸í•˜ê³  **ì£¼ìš” ì˜ê²¬ì˜ ê²½í–¥ì„±**ë§Œ ë°˜ì˜í•©ë‹ˆë‹¤.
- ì–¸ì–´ëŠ” ì…ë ¥ ë°ì´í„°ì˜ ì–¸ì–´(í•œêµ­ì–´/ì˜ì–´ ë“±)ì— ë§ê²Œ ë™ì¼í•˜ê²Œ ìœ ì§€í•©ë‹ˆë‹¤.
"""

# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")

# ì‚¬ìš©ìê°€ ë©”ì‹œì§€ë¥¼ ì…ë ¥í–ˆì„ ë•Œ
if user_input:
    current_messages.append({"role": "user", "content": user_input})

    with st.chat_message("user"):
        st.write(user_input)

    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        
        with st.spinner("YouTube MCPë¥¼ í™œìš©í•˜ì—¬ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”!"):
            full_response = generate_chat_response(current_messages, system_prompt)
            if asyncio.isfuture(full_response):
                full_response = asyncio.run(full_response)
    
        current_messages.append({"role": "assistant", "content": full_response})

    if current_session["title"] == "ìƒˆ ëŒ€í™”":
        current_session["title"] = user_input[:30] + "..." if len(user_input) > 30 else user_input
        st.rerun()